import os
import time
import asyncio
import edge_tts
from dotenv import load_dotenv
from langchain_ollama import OllamaEmbeddings, ChatOllama

class Models:
    def __init__(self):
        # Initialisation des embeddings Ollama
        self.embeddings_ollama = OllamaEmbeddings(model="mxbai-embed-large")
        
        # Initialisation du mod√®le de chat Ollama
        self.model_ollama = ChatOllama(model="llama3.2", temperature=0)

    def get_embedding(self, text):
        return self.embeddings_ollama.embed_query(text)

    def chat_completion(self, prompt):
        response = self.model_ollama.invoke(prompt)
        return response

    async def text_to_speech(self, text, output_file="output.mp3"):
        print("üîä D√©but de la conversion texte en parole...")
        
        communicate = edge_tts.Communicate(text, "en-US-JennyNeural")
        await communicate.save(output_file)

        # V√©rifier si le fichier a bien √©t√© enregistr√©
        if os.path.exists(output_file):
            print(f"‚úÖ Audio enregistr√© avec succ√®s : {output_file}")
        else:
            print("‚ùå Erreur : le fichier audio ne s'est pas enregistr√©.")

        print("üìÇ Fichiers dans le dossier actuel :", os.listdir("."))


# Exemple d'utilisation
if __name__ == "__main__":
    models = Models()
    
    # Exemple d'embedding
    embedding = models.get_embedding("Bonjour, comment vas-tu ?")
    print("Embedding:", embedding[:5], "...")  # Affichage partiel
    
    # Exemple de compl√©tion
    response = models.chat_completion("√âcris un ha√Øku sur l'IA")
    print("R√©ponse AI:", response)
    
    # Convertir le texte en parole
    asyncio.run(models.text_to_speech(response))
